---
title: "How precise is infants' visual concept knowledge?"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

    
output: papaja::apa6_pdf   
#output: cogsci_paper::cogsci_paper
#final-submission: \cogscifinalcopy
---


```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(here)
library(dplyr)
library(lmerTest)
library(broom.mixed)
```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path=here('figures'),
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r}
trial_metadata <- read.csv(here("data","metadata","level-trialtype_data.csv"))
trial_summary_data <- read.csv(here("data","main", "processed_data","level-trials_data.csv"))

usable_trials <- trial_summary_data %>%
  filter(exclude_participant_insufficient_data == 0 & trial_exclusion == 0 & exclude_participant == 0) 

# Merging with similarity information and mean-centering main effects
trials_with_effect_vars <- usable_trials |>
  left_join(trial_metadata) |>
  mutate(age_in_months = SubjectInfo.testAge/30)

mean_age <- trials_with_effect_vars |> distinct(SubjectInfo.subjID, age_in_months) |>
  summarize(mean_age = round(mean(age_in_months),2)) |>
  pull(mean_age)
younger_infants <- trials_with_effect_vars |>
  filter(age_in_months < mean_age)
```

```{r}


prereg_main_effect <- lmer(scale(corrected_target_looking) ~ scale(text_similarity)*scale(age_in_months)
                    + (scale(text_similarity) | SubjectInfo.subjID)
                   # + scale(AoA_Est_target)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)

image_sim_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    + (1 | SubjectInfo.subjID)
                    + (1|Trials.targetImage), 
                    #+ (1|Trials.imagePair), 
                    data = trials_with_effect_vars)

multimodal_sim_effect <- lmer(scale(corrected_target_looking) ~ scale(multimodal_similarity)*scale(age_in_months)
                    + (scale(multimodal_similarity) | SubjectInfo.subjID)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)

main_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    + (scale(image_similarity) | SubjectInfo.subjID)
                    + scale(MeanSaliencyDiff)
                    + scale(AoA_Est_target)
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

aoa_correlation <- tidy(cor.test(trial_metadata$image_similarity, trial_metadata$AoA_Est_target))


tidy_model <- function(main_effect){
  table_data <- tidy(main_effect, effects = "fixed") %>%
  mutate(
    #p.value = 2 * (1 - pnorm(abs(statistic))),  # Calculate p-values for lmer
    p.value = case_when(
      p.value < .001 ~ "<.001", 
      p.value < .01 ~ "<.01",
      p.value < .05 ~ "<.05",
      TRUE ~ sprintf("%.3f", p.value)),
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "scale(age_in_months)" ~ "Age (scaled)",
      #term == "scale(image_similarity)" ~ "Target-distractor image embedding similarity (scaled)",
      TRUE ~ term
    )
  ) %>%
  rename(
    Predictor = term,
    "b" = estimate,
    "SE" = std.error,
    "t" = statistic,  # Note: changed from z to t for lmer
    "p" = p.value
  ) %>%
  mutate(across(c("b", "SE", "t"), ~round(., 2)))
  return(table_data)
}

image_sim_model <- tidy_model(image_sim_effect)
image_sim_predictor <- image_sim_model |> filter(Predictor == "scale(image_similarity)")
multimodal_sim_model <- tidy_model(multimodal_sim_effect)
multimodal_sim_predictor <- multimodal_sim_model |> filter(Predictor == "scale(multimodal_similarity)")
text_sim_model <- tidy_model(prereg_main_effect)
text_sim_predictor <- text_sim_model |> filter(Predictor == "scale(text_similarity)")
main_model <- tidy_model(main_effect)
aoa_predictor <- main_model |> filter(Predictor == "scale(AoA_Est_target)")
saliency_predictor <- main_model |> filter(Predictor == "scale(MeanSaliencyDiff)")
age_predictor <- main_model |> filter(Predictor == "Age (scaled)")

```

# Results
We examined whether infants showed evidence for graded visual concept knowledge. To do so, we analyzed how well infants could identify the referents of visual concepts in naturalistic visual images using distractors that varied in similarity to target images. We found infants looked at the target image when the distractor was more dissimilar to the target image in image similarity space (see Figure 1B; estimated using a linear mixed-effect model: \textit{b}=`r image_sim_predictor |> pull(b)`, \textit{t}=`r image_sim_predictor |> pull(t)`, \textit{p}=`r image_sim_predictor |> pull(p)`). Text similarity measures trended in the same direction but were not significant (`r text_sim_predictor |> pull(b)`, t=`r text_sim_predictor |> pull(t)`, p=`r text_sim_predictor |> pull(p)`). In addition, we anticipated that more difficult words would be more challenging for infants to recognize. Consistent with this prediction, the AoA of the target word correlated inversely with the proportion of time infants looked at the target image (Figure 1C; \textit{b}=-0.10, \textit{t}=-4.14, p\textless.001). Yet, while target word AoA and target-distractor image similarity were not colinear (\textit{r}=`r aoa_correlation |> pull(round(estimate, 2))`, \textit{p}=`r aoa_correlation |> pull(round(p.value,2))`), they did not explain unique variance in this sample.
Finally, we verified that these effects were not driven by differences in how well the stimuli captured infants' visual attention: target-distractor visual saliency differences from a GBVS model did not predict variance in infantsâ€™ looking behaviors in a linear mixed-effects model (b=`r saliency_predictor |> pull(b)`, t=`r saliency_predictor |> pull(t)`, p=`r saliency_predictor |> pull(p)`). 


\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent