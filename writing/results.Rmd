---
title: "How precise is infants' visual concept knowledge?"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

    
output: papaja::apa6_pdf   
#output: cogsci_paper::cogsci_paper
#final-submission: \cogscifinalcopy
---


```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(here)
library(dplyr)
library(lmerTest)
library(broom.mixed)
```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path=here('figures'),
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r}
trial_metadata <- read.csv(here("data","metadata","level-trialtype_data.csv"))
trial_summary_data <- read.csv(here("data","main", "processed_data","level-trials_data.csv"))

usable_trials <- trial_summary_data %>%
  filter(exclude_participant_insufficient_data == 0 & trial_exclusion == 0 & exclude_participant == 0) 

# Merging with similarity information and mean-centering main effects
trials_with_effect_vars <- usable_trials |>
  left_join(trial_metadata) |>
  mutate(age_in_months = SubjectInfo.testAge/30)

mean_age <- trials_with_effect_vars |> distinct(SubjectInfo.subjID, age_in_months) |>
  summarize(mean_age = round(mean(age_in_months),2)) |>
  pull(mean_age)
younger_infants <- trials_with_effect_vars |>
  filter(age_in_months < mean_age)
```

```{r}


prereg_main_effect <- lmer(scale(corrected_target_looking) ~ scale(text_similarity)*scale(age_in_months)
                    + (scale(text_similarity) | SubjectInfo.subjID)
                   # + scale(AoA_Est_target)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)

image_sim_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    #+ scale(AoA_Est_target)
                    + (1 | SubjectInfo.subjID)
                    + (1|Trials.targetImage), 
                    #+ (1|Trials.imagePair), 
                    data = trials_with_effect_vars)

multimodal_sim_effect <- lmer(scale(corrected_target_looking) ~ scale(multimodal_similarity)*scale(age_in_months)
                    + (scale(multimodal_similarity) | SubjectInfo.subjID)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)

main_effect <- lmer(scale(corrected_target_looking) ~ scale(text_similarity)*scale(age_in_months)
                    + (scale(text_similarity) | SubjectInfo.subjID)
                    + scale(MeanSaliencyDiff)
                    + scale(AoA_Est_target)
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)


tidy_model <- function(main_effect){
  table_data <- tidy(main_effect, effects = "fixed") %>%
  mutate(
    p.value = 2 * (1 - pnorm(abs(statistic))),  # Calculate p-values for lmer
    p.value = case_when(
      p.value < .001 ~ "<.001", 
      p.value < .01 ~ "<.01",
      p.value < .05 ~ "<.05",
      TRUE ~ sprintf("%.3f", p.value)),
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "scale(age_in_months)" ~ "Age (scaled)",
      #term == "scale(image_similarity)" ~ "Target-distractor image embedding similarity (scaled)",
      TRUE ~ term
    )
  ) %>%
  rename(
    Predictor = term,
    "b" = estimate,
    "SE" = std.error,
    "t" = statistic,  # Note: changed from z to t for lmer
    "p" = p.value
  ) %>%
  mutate(across(c("b", "SE", "t"), ~round(., 2)))
  return(table_data)
}

image_sim_model <- tidy_model(image_sim_effect)
image_sim_predictor <- image_sim_model |> filter(Predictor == "scale(image_similarity)")
multimodal_sim_model <- tidy_model(multimodal_sim_effect)
multimodal_sim_predictor <- multimodal_sim_model |> filter(Predictor == "scale(multimodal_similarity)")
text_sim_model <- tidy_model(prereg_main_effect)
text_sim_predictor <- text_sim_model |> filter(Predictor == "scale(text_similarity)")
main_model <- tidy_model(main_effect)
aoa_predictor <- main_model |> filter(Predictor == "scale(AoA_Est_target)")
saliency_predictor <- main_model |> filter(Predictor == "scale(MeanSaliencyDiff)")
age_predictor <- main_model |> filter(Predictor == "Age (scaled)")

```

# Results
We analyzed how well infants could identify the referents of common
visual concepts in naturalistic visual images with distractors that varied in similarity to the
target image. Overall, we found an increase in how often infants looked at the target image
when the distractor was dissimilar to the target in either image or text similarity space (see
Figure 1C, estimated using linear mixed-effect models, image similarity: b=`r image_sim_predictor |> pull(b)`, t=`r image_sim_predictor |> pull(t)`, p=`r image_sim_predictor |> pull(p)`; text similarity: b=`r text_sim_predictor |> pull(b)`, t=`r text_sim_predictor |> pull(t)`, p=`r text_sim_predictor |> pull(p)`); that is, children were more likely to look at the correct referent when the distractor was linguistically or visually dissimilar.
However, this was not solely due to differences in visual saliency: visual saliency
differences did not predict variance in infants’ looking behaviors (model: b=`r saliency_predictor |> pull(b)`, t=`r saliency_predictor |> pull(t)`, p=`r saliency_predictor |> pull(p)`). 

We next examined how differences in target word age-of-acquisition  determined accuracy. Age-of-acquisition correlated inversely with looking time (see Fig 1E; model: b=-0.10, t=-4.14, p=\textless.001), in line with our prediction that harder words would be harder to recognize. Accuracy was at chance for our most difficult words like ‘coconut’ and ‘swan’. Additionally, we did not find any interaction between AoA, infant age (age was additionally not predictive of variance (model: b=`r age_predictor |> pull(b)`, t=`r age_predictor |> pull(t)`, p=`r age_predictor |> pull(p)`), and our similarity measures. 

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent