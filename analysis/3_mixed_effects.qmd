```{r message=FALSE}
library(tidyverse)
library(here)
library(lmerTest)
library(MuMIn)
library(lme4)
library(dotenv)
library(broom)
library(broom.mixed)
library(effects)
library(emmeans)


load_dot_env(file=here(".env"))
PROJECT_VERSION = Sys.getenv("PROJECT_VERSION")
source("lmer_helpers.R")
```

### Load data
```{r}
trial_metadata <- read.csv(here("data","metadata","level-trialtype_data.csv"))
trial_summary_data <- read.csv(here("data",PROJECT_VERSION, "processed_data","level-trials_data.csv"))

usable_trials <- trial_summary_data |>
  filter(exclude_participant_insufficient_data == 0 & trial_exclusion == 0 & exclude_participant == 0) 

# Merging with similarity information and mean-centering main effects
trials_with_effect_vars <- usable_trials |>
  left_join(trial_metadata) |>
  mutate(age_in_months = SubjectInfo.testAge/30)
```
Sanity check - making sure all participants have at least 16 trials
```{r}
trials_with_effect_vars |> distinct(SubjectInfo.subjID,Trials.trialID) |> summarize(n=n(),.by=SubjectInfo.subjID) |> filter(n < 20)
```

### Run mixed-effects model
Model 1: This is the model we said we'd run in our pre-reg
```{r}
prereg_main_effect <- lmer(scale(corrected_target_looking) ~ scale(text_similarity)*scale(age_in_months)
                    + (scale(text_similarity) | SubjectInfo.subjID)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)


summary(prereg_main_effect)
```
Currently, it looks like text_similarity is not predictive. Let me estimate using tidy()
```{r}
tidy_model <- function(main_effect){
  table_data <- tidy(main_effect, effects = "fixed") %>%
  mutate(
    p.value = 2 * (1 - pnorm(abs(statistic))),  # Calculate p-values for lmer
    p.value = case_when(
      p.value < .001 ~ "<.001", 
      p.value < .01 ~ "<.01",
      p.value < .05 ~ "<.05",
      TRUE ~ sprintf("%.3f", p.value)),
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "scale(age_in_months)" ~ "Age (scaled)",
      #term == "scale(image_similarity)" ~ "Target-distractor image embedding similarity (scaled)",
      TRUE ~ term
    )
  ) %>%
  rename(
    Predictor = term,
    "b" = estimate,
    "SE" = std.error,
    "t" = statistic,  # Note: changed from z to t for lmer
    "p" = p.value
  ) %>%
  mutate(across(c("b", "SE", "t"), ~round(., 2)))
  return(table_data)
}
prereg_model <- tidy_model(prereg_main_effect)
prereg_model
```
Now it is significant..

Swapping text similarity with image similarity:
```{r}
image_sim_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    + (scale(image_similarity) | SubjectInfo.subjID)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)
```
running into a singular fit, I tried removing each of the random effects but only removing the random slope of image_similarity fixed this, doesn't seem very promising but it is still significant
```{r}
image_sim_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    + (1 | SubjectInfo.subjID)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)
summary(image_sim_effect)
```
Let's try removing that random slope from the text model for consistency
```{r}
text_sim_effect_short <- lmer(scale(corrected_target_looking) ~ scale(text_similarity)*scale(age_in_months)
                    + (1 | SubjectInfo.subjID)
                    + (1|Trials.targetImage) 
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)
summary(text_sim_effect_short)
```
Still comparable to the old model, looking back up, similarity and image pair explained very little variance to begin with so maybe this is ok.

Now for the fun stuff: adding in our covariates
```{r}
main_image_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage)
                    + (1|Trials.imagePair), 
                    data = trials_with_effect_vars)
```
Singular again!

```{r}
main_image_effect <- lmer(scale(corrected_target_looking) ~ scale(image_similarity)*scale(age_in_months)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

main_text_effect <- lmer(scale(corrected_target_looking) ~ scale(text_similarity)*scale(age_in_months)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)
summary(main_image_effect)
summary(main_text_effect)
r.squaredGLMM(main_text_effect)
```
Only the text similarity effect is significant which is interesting.

Checking if text similarity and image similarity are differently correlated with AoA
```{r}
cor.test(trial_metadata$AoA_Est_target, trial_metadata$image_similarity)
cor.test(trial_metadata$AoA_Est_target, trial_metadata$text_similarity)
```
Well insignificant p-values but there is a higher R^2 I guess

### Alternate window analyses

Basline window as a covariate
```{r}
baseline_covariate_looking_text <- lmer(scale(mean_target_looking_critical_window) ~ scale(age_in_months)*scale(text_similarity)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + scale(mean_target_looking_baseline_window)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

baseline_covariate_looking_image <- lmer(scale(mean_target_looking_critical_window) ~ scale(age_in_months)*scale(image_similarity)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + scale(mean_target_looking_baseline_window)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

summary(baseline_covariate_looking_text)
summary(baseline_covariate_looking_image)
```
Similar predictions to our original model.

Adding window type as a covariate
```{r}
window_type_covariattrials_with_effect_vars
baseline_covariate_looking_text <- lmer(scale(mean_target_looking_critical_window) ~ scale(age_in_months)*scale(text_similarity)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + scale(mean_target_looking_baseline_window)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

baseline_covariate_looking_image <- lmer(scale(mean_target_looking_critical_window) ~ scale(age_in_months)*scale(image_similarity)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + scale(mean_target_looking_baseline_window)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

```

Using a shorter critical window
```{r}
short_image_effect <- lmer(scale(corrected_target_looking_short) ~ scale(image_similarity)*scale(age_in_months)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)

short_text_effect <- lmer(scale(corrected_target_looking_short) ~ scale(text_similarity)*scale(age_in_months)
                    + scale(AoA_Est_target)
                    + scale(MeanSaliencyDiff)
                    + (1 | SubjectInfo.subjID) 
                    + (1|Trials.targetImage), 
                    data = trials_with_effect_vars)
summary(short_image_effect)
summary(short_text_effect)
r.squaredGLMM(main_text_effect)
```
Well age is significant and seems to soak up the similarity effects we found.

